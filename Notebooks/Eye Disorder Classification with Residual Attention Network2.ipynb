{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from Code.ResidualAttentionNetwork import ResidualAttentionNetwork\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data, download from Kaggle: https://www.kaggle.com/paultimothymooney/kermany2018\n",
    "\n",
    "train_dir = \"/pylon5/cc5614p/deopha32/eye_images/train\"\n",
    "test_dir = \"/pylon5/cc5614p/deopha32/eye_images/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    validation_split=0.33\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_dir, \n",
    "    shuffle=True,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "valid_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_dir, \n",
    "    shuffle=True,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    shuffle=False,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode=None,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH=32\n",
    "IMAGE_HEIGHT=32\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=1\n",
    "IMAGE_SHAPE=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)\n",
    "batch_size=32\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../Saved_Model/eye-disorder-model-{epoch:02d}-{val_acc:.2f}.h5\"\n",
    "\n",
    "# early_stop = EarlyStopping(monitor='val_acc',  verbose=1, patience=50)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_acc', verbose=1, save_best_only=True)\n",
    "csv_logger = CSVLogger(\"../Saved_Model/model_history.csv\", append=True)\n",
    "\n",
    "callbacks = [checkpoint, csv_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model = ResidualAttentionNetwork(\n",
    "                input_shape=IMAGE_SHAPE, \n",
    "                n_classes=num_classes, \n",
    "                activation='softmax').build_model()\n",
    "\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit_generator(generator=train_generator,\n",
    "                        steps_per_epoch=STEP_SIZE_TRAIN, verbose=1, callbacks=callbacks,\n",
    "                        validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n",
    "                        epochs=epochs, use_multiprocessing=True, workers=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Resume Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "#     model = load_model(model_path)\n",
    "\n",
    "#     history = model.fit_generator(generator=train_generator,\n",
    "#                         steps_per_epoch=STEP_SIZE_TRAIN, verbose=1, callbacks=callbacks,\n",
    "#                         validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n",
    "#                         epochs=epochs, use_multiprocessing=True, workers=40, initial_epoch=50)\n",
    "\n",
    "# model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "ax1.set_xticks(np.arange(1, 10, 1))\n",
    "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "ax2.plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "ax2.set_xticks(np.arange(1, 10, 1))\n",
    "\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate_generator(valid_generator, STEP_SIZE_VALID, verbose=1, use_multiprocessing=True, workers=40)\n",
    "print(\"Test: accuracy = %f  ;  loss = %f \" % (accuracy, loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
